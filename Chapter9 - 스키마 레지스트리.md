# 카프카 운영과 모니터링

## 서론

- 카프카를 장애 없이 안정적으로 운영하는 것은 중요한 일
- 다른 애플리케이션들에 비해 굉장히 안정적으로 동작하기 때문에 때로는 클러스터를 구성해두고 카프카 서버에 접근조차 하지 않는 일도 많음
- 장애가 발생하지 않도록 사전 예방 조치를 취하는 것이 중요함
- `카프카`와 `카프카가 실행되고 있는 하드웨어 리소스` 둘 다 모니터링 해야 함

## 안정적인 운영을 위한 주키퍼와 카프카 구성

### 주키퍼 구성

- 아파치 카프카 오픈소스 진영에서는 카프카의 코디네이터 역할을 하는 주키퍼의 의존성을 제거하려는 움직임이 있음 (이미 했죠?)
- 하지만 아직 주키퍼사용하는 버전을 쓰게 될 수도 있으니 살펴보겠습니다.

### 주키퍼 서버 수량

- 주키퍼는 기본적으로 과반수 구성을 기반으로 동작하므로 반드시 홀수로 구성해야 함. (최소 3대)
    - 3대 구성시 ⇒ 1대 장애 허용
    - 5대 구성시 ⇒ 2대 장애 허용
- 카프카의 사용량이 높지 않으며 매우 중요한 클러스터가 아니라면 **3대**
- 회사에서 핵심 중앙 데이터 파이프라인으로 이용중이고 사용량이 높다면 **5대**

### 주키퍼 하드웨어

- 주키퍼는 높은 하드웨어 리소스를 요구하지 않음
    - 물리 메모리는 4~8GB, 디스크는 240G, 480G SSD를 추천
    - 주키퍼에서 필요로 하는 힙 메모리는 일반적으로 1~2GB이며, 나머지는 OS영역에서 사용
    - 따라서 과도한 주키퍼에 물리 메모리를 장착하는 것은 오히려 메모리를 낭비하는 일이 될 수 있음.
    - 트랜잭션이나 스냅샷 로그들을 로컬 디스크에 저장하며 일반적인 SAS 디스크보다는 쓰기 성능이 좋은 SSD 디스크 추천
    - 주키퍼와 카프카 간에는 메타데이터 정도만을 주고받으므로 네트워크 카드는 1G 이더넷 카드로 구성하면 됌.

### 주키퍼 배치

- 물리 서버를 배치하는 경우 일반적으로 데이터 센터 내에 랙 마운트를 함
    - 하나의 랙에 모든 주키퍼 서버를 마운트해 배치하는 것은 매우 위험
    - 항온 항습 장치, UPS 등의 안정 장비를 구비한 데이터 센터이지만, 때때로 전원 장애나 네트워크 장애도 발생할 수 있음.
- 각각 다른 랙에 분산 배치하는 방안을 권장하며, 전원 이중화나 스위치 이중화 장치 등도 고려해야 함.
- AWS와 같은 퍼블릭 클라우드에서 EC2 인스턴스를 구성해 사용하기도 하는데 AWS에서도 분산 배치를 위해 가용 영역을 운영하므로 가능한 2개 또는 3개의 가용 영역에 분산해 구성하는 것을 추천

## 카프카 구성

### 카프카 서버 수량

- 주키퍼와 다르게 쿼럼(과반수) 구성이 필요하지 않음 ⇒ 반드시 홀수일 필요 없다.
- 카프카에서 추천하는 안정적인 리플리케이션 팩터 수인 3으로 토픽을 구성하기 위해서는 최소 3대의 브로커가 필요 ⇒ 따라서 최소 구성을 원한다면 3대가 적당함.
- 처음부터 과도하게 수량을 산정해 구성하는 경우도 있는데 손쉬운 서버 확장이 장점이므로 현재 꼭 필요한 수량만큼만 구성하는 편이 좋음.

### 카프카 하드웨어

- 주키퍼와 달리 카프카의 CPU 사용률은 높은 편임
    - 프로듀서나 컨슈머의 처리량을 높이기 위해 배치와 압축 기능을 많이 적용하는데, 그에 따른 압축이나 해제에도 많은 리소스가 소모됌.
    - 그렇다고 해서 최신의 고성능 CPU만 고집할 필요는 없으며 코어수가 많은 CPU를 권장
- 메모리는 32GB부터 256GB까지 다양하게 선택할 수 있는데, 카프카에서 요구하는 JVM 힙 크기는 일반적으로 6GB이므로 이보다 큰 물리 메모리가 필요
    - 힙 크기를 제외한 나머지 물리 메모리는 모두 페이지 캐시로 사용하여 빠른 처리를 도움
    - 따라서 메모리가 여유가 있어야 성능에 도움이 됌.
    - 128GB, 256GB 등 가용할 수 있는 서버 메모리가 있다면 그대로 사용하고, 조금 타이트 하게 운영한다면 최소 32GB 이상 구성하는 것을 추천
- 디스크의 경우 SSD, SAS, SATA, NAS등 여러 선택지가 있는데 성능이 가장 낮은 SATA 디스크를 선택해도 괜찮습니다.
    - 저성능 SATA 디스크를 사용해도 높은 성능을 보장하는 이유는 로그 마지막에 순차적으로 쓰는 방식으로 로그를 기록하기 때문
    - 다만 브로커 한 대에 하나의 물리 디스크를 사용하는 것이아니라 병렬 처리를 위해 서버에 약 10개 정도의 디스크를 장착
    - 간혹 물리적 디스크 크기가 너무 작아 토픽 파티션의 로그가 가득 차는 경우가 있는데, 토픽의 보관 주기를 충분하게 설정하려면 4TB 용량 이상의 디스크를 권장
- NAS 디스크도 하나의 대안이 될 수 있지만, 모든 브로커가 하나의 NAS만 바라보고 있다가 NAS 장애가 발생한다면 이는 매우 큰 문제가 될 수 있으므로 비용과 안정성 측면을 고려해 NAS는 사용하지 않는것 권장
- AWS에서 EC2 인스턴스를 이용해 카프카 설치 및 운영할 수 있는데, EBS(Elastic Block Store)는 안정적이라고 합니다.
- 카프카의 네트워크 카드는 10G 이더넷 카드로 구성하는 것을 추천하며, 브로커 한 대당 네트워크 사용량 비율이 50%가 넘지 않도록 최대한 토픽을 분산해 운영해야 함.
    - 디스크의 장애 복구 또는 신규 브로커 추가로 인해 카프카 클러스터 사이에는 대량의 데이터 이동이 발생
    - 이 때 많은 트래픽을 사용하게 되므로 네트워크 대역폭은 충분히 확보해둬야 함.

### 카프카 배치

- 주키퍼와 마찬가지로 모든 카프카 서버를 하나의 랙에 마운트하는 것은 매우 위험함.
    - 여러 랙에 분산시켜 카프카 서버 배치하는 방식 추천
    - 전원 이중화, 스위치 이중화 고려
    - 멀티 AZ 고려

## 모니터링 시스템 구성

- 잘 갖춰진 모니터링 도구를 이용해 카프카의 현재 상태를 정확하게 파악한다면 미래에 일어날 이슈나 문제를 사전에 예측해 미리 조치할 수 있음
- 장애도 빠르게 감지해 신속한 장애 처리가 가능함.
- 카프카를 모니터링하는 방법은 여러 가지가 있지만, 그중에서 대표적인 모니터링은 애플리케이션 로그 분석과 JMX르 이용해 브로커들의 메트릭 정보를 확인하는 방법
    - 브로커의 로그 수집 및 분석에 대해서는 ‘카프카, 데이터 플랫폼의 최강자’ 7장 ‘카프카를 활용한 데이터 파이프라인 구축’에서 NIFI, ElasticSearch 등을 이용하는 방법을 설명했으니 참고

### 애플리케이션으로서 카프카의 로그 관리와 분석

- 카프카는 애플리케이션에서 발생하는 모든 로그를 브로커의 로컬 디스크에 기록하고 있음.
- 관리자는 이 로그를 활용해 카프카의 현재 상태나 이상 징후 등을 발견하거나 이상 증상 발생 시 원인을 찾음.
- 카프카는 애플리케이션 로그 관리를 위해 자바 기반의 로깅 유틸리티인 아파치 `log4j`를 이용함
    - `log4j` 는 애플리케이션의 레벨별로 로깅이 가능하며, 관리자는 로그의 레벨을 보고 상황의 심각성을 유추 할 수 있음.
    - 카프카에서는 다음과 같이 로그 레벨을 사용하고 있음.

| 로그 레벨 | 설명 |
| --- | --- |
| TRACE | DEBUG보다 상세한 로그 기록 |
| DEBUG | 내부 애플리케이션 상황에 대한 로그를 기록(INFO 로그 레벨보다 상세한 로그 기록) |
| INFO | 로그 레벨의 기본값이며, 일반적인 정보 수준의 로그 기록 |
| WARN | INFO 로그 레벨보다 높은 개념으로, 경고 수준의 로그 기록 |
| ERROR | 경고 수준을 넘어 런타임 에러나 예상하지 못한 에러 로그 기록 |
| FATAL | 로그 레벨 중 최종 단계이며, 심각한 오류로 인한 애플리케이션 중지 등의 로그를 기록 |
- 표와 같이 카프카 애플리케이션에서는 여섯 가지의 로그 레벨이 있으며 이 중 INFO 로그 레벨이 카프카 애플리케이션 로그의 기본값임.
- 간혹 카프카의 이슈가 발생하면 관리자는 INFO 수준보다 상세한 로그를 확인하고 싶을 것.
    - 카프카에서 제공하는 log4j의 설정의 변경을 통해 관리자는 언제든지 로그 레벨을 변경할 수 있음.

```bash
# log4j.properties
# Change the two lines below to adjust the general broker logging level (output to server.log and stdout)
log4j.logger.kafka=INFO
log4j.logger.org.apache.kafka=INFO
```

- 위 설정을 `DEBUG`로 변경 후 재시작하면 이제부터는 `DEBUG` 레벨의 로그도기록하기 시작함.
- 주의할 점은 로그 레벨을 `INFO`에서 `DEBUG` 또는 `TRACE` 등으로 낮출 경우, 예상보다 많은 로그가 발생하며 이 모든 로그는 로컬 디스크에 기록됩니다.
    - 이로 인해 브로커의 여유 디스크 공간이 로그 파일로 가득 찰 수 있음.
    - 로그 레벨을 변경하기 전에 여유 디스크 공간이 충분한지 확인하며, 꼭 필요할 때에만 변경할 것을 권장

- 각 로그파일들이 어떤 정보를 기록하고 있을까

| 로그 파일 이름 | 설명 |
| --- | --- |
| server.log | 브로커 설정 정보와 정보성 로그 등을 기록함. 브로커를 재시작하는 경우 브로커의 옵션 정보가 기록됨 |
| state-change.log | 컨트롤러부터 받은 정보를 기록함. |
| kakfa-request.log | 클라이언트로부터 받은 정보를 기록함 |
| log-cleaner.log | 로그 컴팩션 동작들을 기록함 |
| controller.log | 컨트롤러 관련 정보를 기록함 |
| kafka-authorizer.log | 인증과 관련된 정보를 기록함 |
- 이처럼 카프카에서는 log4j를 이용해 여러 로그 파일들을 기록함
- 관리자는 디버깅이나 오류 확인 및 분석이 필요할 경우 로그 레벨 변경할 수 있음

### JMX를 이용한 카프카 메트릭 모니터링

- 로그뿐 아니라 카프카 클러스터의 상태 및 이상 유무를 한눈에 빠르게 확인할 수 있어야 함.
- JMX는 자바로 만든 애플리케이션의 모니터링을 위한 도구를 제공하는 자바 API
    - MBean(Managed Bean)이라는 객체로 표현 됌.
    - 카프카 관리자는 JMX를 이용해 카프카의 주요 메트릭들을 그래프와 같은 형태로 한눈에 확인할 수 있음.
- JMX를 이용해 카프카의 주요 메트릭을 확인하려면 몇 가지 준비 절차가 필요함.
    - 브로커에 JMX 포트를 오픈
    - JMX에서 제공하는 메트릭 정보를 관리자가 GUI 형태로 볼 수 있도록 해야함
    - 프로메테우스와 익스포터를 이용한 방법을 알아보자.

### 카프카 JMX 설정 방법

- 카프카에서 JMX를 사용할 수 있도록 설정하는 방법은 여러 가지가 있다.
- 이 책에서는 systemd의 환경 변수 옵션을 추가하는 방법으로 진행
- 2.2절에서 설치 과정에서 환경 변수 옵션은 이미 추가되어 있음.

```bash
$ cat /usr/local/kafka/config/jmx
JMX_PORT=9999
```

이제 JMX 포트가 활성화됐는지 리눅스의 netstat을 이용해 확인해보면..

```bash
$ netstat -ntl | grep 9999
tcp      0.     0 :::9999          :::*            LISTEN
```

- JMX 포트가 LISTEN 상태인 것으로 보아 JMX 설정은 잘되었음.

### 프로메테우스 설치

- 프로메테우스를 활용하여 애플리케이션의 성능과 상태, 인프라의 성능도 손쉽게 확인 가능
- 그라파나와 연동하여 많이 사용함
